{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22050b0f-6e16-4a0c-80cc-263da4876292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27702a6b-65a3-4511-83c2-fad82d2567a7",
   "metadata": {},
   "source": [
    "# W&B API for CI/CD\n",
    "\n",
    "The following are examples of operations you can perform with the `wandb` python client that might be relevant for CI/CD.\n",
    "\n",
    "Perquisite: the environment variable `WANDB_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588e92f2-4668-4275-a181-87aa71cefd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.getenv('WANDB_API_KEY'), 'You must set the WANDB_API_KEY environment variable'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0b1626-e001-4f05-bc02-beb48bc86d76",
   "metadata": {},
   "source": [
    "## Getting metrics tied to the current production model\n",
    "\n",
    "We can get the production model from the registry, then get the metrics via lineage from the associated run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdf6a37-dee3-4f0e-924a-cf05c7979c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhamelsmu\u001b[0m (\u001b[33mav-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/hamel/github/wandb-cicd/client/wandb/run-20230123_120325-qmjtg84e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/av-team/wandb-cicd-client/runs/qmjtg84e\" target=\"_blank\">vague-yogurt-2</a></strong> to <a href=\"https://wandb.ai/av-team/wandb-cicd-client\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/av-team/wandb-cicd-client\" target=\"_blank\">https://wandb.ai/av-team/wandb-cicd-client</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/av-team/wandb-cicd-client/runs/qmjtg84e\" target=\"_blank\">https://wandb.ai/av-team/wandb-cicd-client/runs/qmjtg84e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(job_type=\"CI/CD\")\n",
    "path = 'av-team/model-registry/'\n",
    "model_name = 'BDD Semantic Segmentation'\n",
    "version = 'production'\n",
    "\n",
    "artifact = run.use_artifact(f'{path}{model_name}:{version}', \n",
    "                            type='model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86885dd-c112-4930-9dcd-abec5d8bdc5c",
   "metadata": {},
   "source": [
    "Get the run that created the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c2645-b132-4089-893d-ac8274382d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = artifact.logged_by()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9845cf39-8617-42a9-b547-81961ebd73f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'person_iou': 0.13954558401437303,\n",
       " 'final_vehicle_iou': 0.7561426671932289,\n",
       " 'bicycle_iou': 0,\n",
       " 'final_road_iou': 0.8347413133027304,\n",
       " 'final_bicycle_iou': 0,\n",
       " 'final_traffic_sign_iou': 0.05314886217585242,\n",
       " 'road_iou': 0.8379052798838932,\n",
       " 'vehicle_iou': 0.7598675070628712,\n",
       " 'background_iou': 0.921853196957014,\n",
       " 'traffic_sign_iou': 0.04609753307660045,\n",
       " 'traffic_light_iou': 0.1546196566812521,\n",
       " 'final_traffic_light_iou': 0.11524698900331648,\n",
       " 'final_person_iou': 0.20271520471610835,\n",
       " 'final_background_iou': 0.920883500388814}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_iou_metrics(run):\n",
    "    return {k:v for k,v in run.summary.items() if '_iou' in k}\n",
    "\n",
    "get_iou_metrics(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84628de-23ea-4642-8ac9-b193c86768fd",
   "metadata": {},
   "source": [
    "## Getting metrics for a run ID\n",
    "\n",
    "This is useful if you want to get metrics for a particular experiment ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f28ab9-2b2f-40aa-92ed-2c7d96e2639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path = 'av-team/mlops-course-001/wlt1r8k7'\n",
    "api = wandb.Api()\n",
    "run = api.run(run_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860201db-b17a-45f8-9fa9-88ba385efec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'traffic_sign_iou': 0.0001342732460557234,\n",
       " 'road_iou': 0.8467596086120717,\n",
       " 'final_person_iou': 0,\n",
       " 'traffic_light_iou': 0.07797093928386092,\n",
       " 'person_iou': 0,\n",
       " 'bicycle_iou': 0,\n",
       " 'final_traffic_light_iou': 0.09025893958076447,\n",
       " 'background_iou': 0.9209043224804184,\n",
       " 'final_road_iou': 0.8422501240160545,\n",
       " 'vehicle_iou': 0.7519784886198334,\n",
       " 'final_bicycle_iou': 0,\n",
       " 'final_vehicle_iou': 0.7519664371203332,\n",
       " 'final_traffic_sign_iou': 0.00013421917992081068,\n",
       " 'final_background_iou': 0.9194038173285132}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_iou_metrics(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db442804-ce15-4cad-9e76-51cdefc37d85",
   "metadata": {},
   "source": [
    "## Getting metrics for a run with a tag\n",
    "\n",
    "It's better to use the [Mongo API](https://docs.wandb.ai/guides/track/public-api-guide#querying-multiple-runs) instead of downloading and iterating through each run if possible.\n",
    "\n",
    "The use case for this is if you wanted to compare a particular run with another run that you have tagged, such as \"baseline\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a04044-940f-49b9-a95c-2c29a7ad02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "tags= ['candidate']\n",
    "\n",
    "baseline_runs=api.runs('av-team/mlops-course-001', \n",
    "                       {\"tags\": {\"$in\": tags}}) # this is the Mongo Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b588a18a-6cfd-4d3f-ae85-5fa1ac6f6153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scarlet-armadillo-502\n",
      "fine-sweep-63\n"
     ]
    }
   ],
   "source": [
    "for run in baseline_runs:\n",
    "    print(run.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1485a207-b42f-4359-906f-dec6ecda9c1a",
   "metadata": {},
   "source": [
    "## Promote a model to the registry\n",
    "\n",
    "This is also might be something you could do as part of a CI/CD process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321a2d50-8e65-4241-9f9c-d75b70b7fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'av-team/model-registry/BDD Semantic Segmentation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5075757-8635-469e-bd37-d43b6361f2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path = 'av-team/mlops-course-001/2wpuuc70' # this is the run id\n",
    "api = wandb.Api()\n",
    "run = api.run(run_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85afd436-a899-40eb-b18f-30dcbbbaf5a0",
   "metadata": {},
   "source": [
    "Get the model from the run and promote it to the registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e3ac0-4ff3-45a5-a3c8-b9fe30e3f9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "art = [a for a in run.logged_artifacts() if a.type == 'model']\n",
    "\n",
    "if art:\n",
    "    assert len(art) == 1, 'More then 1 artifact of type model!'\n",
    "    art[0].link(path, aliases=['new-model-demo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03e85e0-2a88-48d5-b712-99c0fcf5c415",
   "metadata": {},
   "source": [
    "We can see a model in the registry like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac95585-02ef-4243-a1fc-f898d4c478a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "versions = api.artifact_versions('model', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30da5501-6dea-4fe0-96df-1a21af14964c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model version: v3 with tags: ['new-model-demo', 'latest']\n",
      "Model version: v2 with tags: ['prod candidate', 'demo']\n",
      "Model version: v1 with tags: ['staging', 'production']\n",
      "Model version: v0 with tags: []\n"
     ]
    }
   ],
   "source": [
    "for v in versions:\n",
    "    print(f'Model version: {v.version} with tags: {v.aliases}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80af424f-b6dd-4e19-932d-83630787a827",
   "metadata": {},
   "source": [
    "See the URL for the model registry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f29e3e-4fad-4999-b31a-26b31555da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_model = versions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e2cb6a-8fe9-4f58-a9b5-86d49ee4bbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://wandb.ai/av-team/registry/model?selectionPath=av-team%2Fmodel-registry%2FBDD+Semantic+Segmentation&version=v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dcf14d-9ca1-4e5b-a774-06595a995fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://wandb.ai/av-team/registry/model?selectionPath=av-team%2Fmodel-registry%2FBDD+Semantic+Segmentation&version=v3'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import urlencode\n",
    "query = urlencode({'selectionPath': path, 'version': latest_model.version})\n",
    "registry_url = f'https://wandb.ai/{latest_model.entity}/registry/model?{query}'\n",
    "registry_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9df6a41-a71b-4c76-aa03-b904ec8431e2",
   "metadata": {},
   "source": [
    "## Run Comparison\n",
    "\n",
    "[This notebook](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/intro/Report_API_Quickstart.ipynb#scrollTo=C3KKJGepCVW4) documents how to use the wandb python client to create a report.  [These docs](https://docs.wandb.ai/guides/reports) describe how to [create](https://docs.wandb.ai/guides/reports/create-a-report) and [edit](https://docs.wandb.ai/guides/reports/edit-a-report) a report.  Make sure you click on the `Python SDK` tab on any "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c4909f-a551-4377-8028-13a12c499b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Thanks for trying out the Report API!\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: For a tutorial, check out https://colab.research.google.com/drive/1CzyJx1nuOS4pdkXa2XPaRQyZdmFmLmXV\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Try out tab completion to see what's available.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   ∟ everything:    `wr.<tab>`\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       ∟ panels:    `wr.panels.<tab>`\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       ∟ blocks:    `wr.blocks.<tab>`\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       ∟ helpers:   `wr.helpers.<tab>`\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       ∟ templates: `wr.templates.<tab>`\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: For bugs/feature requests, please create an issue on github: https://github.com/wandb/wandb/issues\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import wandb.apis.reports as wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6d1211-81e1-4358-a7c7-a5f19efbe6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'my-report-project'\n",
    "ENTITY = 'hamelsmu'\n",
    "\n",
    "report = wr.Report(\n",
    "    entity=ENTITY,\n",
    "    project=PROJECT,\n",
    "    title='Compare Runs',\n",
    "    description=\"A demo of comparing runs programatically\"\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28117643-573f-4b82-b10a-4cdaebf193e9",
   "metadata": {},
   "source": [
    "We can compare two runs like so, and save the report.  In a Jupyter notebook, a preview of the report will automatically appear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed2f943-39a2-475a-a110-1c5471abec00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://wandb.ai/hamelsmu/my-report-project/reports/Compare-Runs--VmlldzozMzk5MTE1?jupyter=true\" style=\"border:none;width:100%;height:1024px;\"></iframe>"
      ],
      "text/plain": [
       "Report(project='my-report-project', entity='hamelsmu', title='Compare Runs', description='A demo of comparing runs programatically', width='readable', blocks=[PanelGrid(runsets=[Runset(entity='hamelsmu', project='my-report-project', name='Run Comparison', query='', filters={'$or': [{'$and': [{'displayName': {'$in': ['bountiful-badger-2', 'dastardly-duck-4']}}]}]}, order=['-CreatedTimestamp'])], panels=[RunComparer(diff_only='split')])])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg = wr.PanelGrid(\n",
    "    runsets=[\n",
    "        wr.Runset(ENTITY, PROJECT, \"Run Comparison\").set_filters_with_python_expr(\"Name in ['bountiful-badger-2', 'dastardly-duck-4']\")\n",
    "    ],\n",
    "    panels=[\n",
    "        wr.RunComparer(diff_only='split', layout={'w': 24, 'h': 15}),\n",
    "    ]\n",
    ")\n",
    "\n",
    "report.blocks = report.blocks[:1] + [pg] + report.blocks[1:]\n",
    "report.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb8dc24-03d4-4674-a9fd-ba649ec9e235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://wandb.ai/hamelsmu/my-report-project/reports/Compare-Runs--VmlldzozMzk5MTE1'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7198e8f-323c-41f2-9134-25022269903e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
